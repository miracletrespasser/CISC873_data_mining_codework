{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nh-anmla-FV0"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is the input? What is the output? What data mining function is required? What could be the challenges? What is the impact? What is an ideal solution?<br>\n",
        "Input: profile of the two people in a matching date<br>\n",
        "output: 1 for success date and 0 for unsuccessful date<br>\n",
        "Chanlenge:Find the most suitable model and parameter for the prediction task. It's really hard for the test score to break through 0.9.<br>\n",
        "Impact: Multiple parameter tuning has to be done to find the best setting, which increases the training time greatly from a few minutes to a few 10 minutes.<br>\n",
        "Ideal Solution: The model should predict profiles of every successfully matched couple as a 1 and unsuccessfulk ones should be predicted 0. The means, every couple that predicted a 1 should be able to have a good time with each other; for the couples predicted a 0, wish they better luck next time. \n"
      ],
      "metadata": {
        "id": "7OxZuO6jgDYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q:What is the experimental protocol used and how was it carried out? What preprocessing steps are used? <br>\n",
        "A:The purporse of the experiment is to predict whether the date will be successful given the profile of two people.<br>\n",
        "The materials are pre-splitted datasets train_new.csv and test_new.csv. The evironment is google colab notebook. <br>\n",
        "Methodology:<br>\n",
        "Grid search,Random search and Bayesian search models are used to analyze and evaluate the data.<br>\n",
        "First, do some preprocessing with the original data(done in the walkthrough notebook). The numerical categorical data processing is done through the pipeline.<br>\n",
        "Then, use the default setting (already done in the notebook)without any parameter tuning or extra data preprocessing in the walkthrough notebook to set up the model. Train the model with untuned training data and generate validation score using validation data.<br>\n",
        "After that, tune the hyperparameter or do extra data preprocessing and repeat the process and see if there is improvements in validation score. For each of the three models, 2 parameter tunes are done.<br>\n",
        "<br>"
      ],
      "metadata": {
        "id": "7RpR8Zu_Jjrr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Pk4nXGq-FV1",
        "outputId": "1e620c9a-f9f1-4d4d-bc03-68793b7457a7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5909, 192)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Extract data from the csv files\n",
        "data = pd.read_csv('train.csv')\n",
        "data_test = pd.read_csv('test.csv')\n",
        "data.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "UVn6pmoI-FV2",
        "outputId": "11653bb8-4f89-46e7-8712-b6549bc81a7e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f536b8f3b90>"
            ]
          },
          "metadata": {},
          "execution_count": 4
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUIklEQVR4nO3df4xld1nH8fdjS2np4G5/4GSzbdwSGkjtSmFvakmNmWkpAjW2fzTYpsFFayZRQZQa2Woimmhc1IpYTXRjiWuyMq2lzWxKEOvSkZhIdQcK2x/UXeoWu5YdZX/gYCMuPv5xv7MOs3d3zt65P+Z7fb+SyT3ne8+553lmTz89851750RmIkmqz3cNuwBJUncMcEmqlAEuSZUywCWpUga4JFXq3EEe7NJLL81NmzZ1te83v/lNLrzwwt4WtIbYX91Gub9R7g3q6G9ubu7fM/M1y8cHGuCbNm1i7969Xe07OzvLxMREbwtaQ+yvbqPc3yj3BnX0FxEvdBp3CkWSKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckio10E9irsa+Q8d5z7ZPDvy4B7ffPPBjSlITXoFLUqUMcEmqlAEuSZUywCWpUga4JFWqUYBHxC9ExNMR8VREfDwizo+IKyLiiYg4EBEPRMR5/S5WkvR/VgzwiNgI/BzQysyrgXOA24EPAx/JzNcBR4G7+lmoJOk7NZ1CORe4ICLOBV4FvATcADxUnt8J3Nr78iRJp7NigGfmIeB3ga/SDu7jwBxwLDNPlM1eBDb2q0hJ0qkiM8+8QcRFwCeAHwOOAX9J+8r718r0CRFxOfCpMsWyfP8pYApgfHx8y/T0dFeFzh85zuGXu9p1VTZvXDeQ4ywsLDA2NjaQYw2D/dVrlHuDOvqbnJycy8zW8vEmH6V/K/DPmflvABHxMHA9sD4izi1X4ZcBhzrtnJk7gB0ArVYru7156H27Zrh33+A/+X/wzomBHKeGG6uuhv3Va5R7g7r7azIH/lXguoh4VUQEcCPwDPA4cFvZZisw058SJUmdNJkDf4L2lMnngX1lnx3AB4EPRMQB4BLg/j7WKUlaptGcRGZ+CPjQsuHngWt7XpEkqRE/iSlJlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqtSKAR4Rr4+IJ5d8fSMifj4iLo6IxyJif3m8aBAFS5LamtxS7bnMvCYzrwG2AP8JPAJsA/Zk5pXAnrIuSRqQs51CuRH4Sma+ANwC7CzjO4Fbe1mYJOnMIjObbxzxMeDzmfmHEXEsM9eX8QCOLq4v22cKmAIYHx/fMj093VWh80eOc/jlrnZdlc0b1w3kOAsLC4yNjQ3kWMNgf/Ua5d6gjv4mJyfnMrO1fLxxgEfEecC/At+XmYeXBnh5/mhmnnEevNVq5d69e8+y9Lb7ds1w775G92DuqYPbbx7IcWZnZ5mYmBjIsYbB/uo1yr1BHf1FRMcAP5splHfQvvo+XNYPR8SG8uIbgPnVlylJaupsAvwO4ONL1ncDW8vyVmCmV0VJklbWKMAj4kLgJuDhJcPbgZsiYj/w1rIuSRqQRpPKmflN4JJlY1+n/a4USdIQ+ElMSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1Klmt6RZ31EPBQRX46IZyPiLRFxcUQ8FhH7y+MZb2gsSeqtplfgHwX+KjPfALwReBbYBuzJzCuBPWVdkjQgKwZ4RKwDfgi4HyAzv5WZx4BbgJ1ls53Arf0qUpJ0qsjMM28QcQ2wA3iG9tX3HPB+4FBmri/bBHB0cX3Z/lPAFMD4+PiW6enprgqdP3Kcwy93teuqbN64biDHWVhYYGxsbCDHGgb7q9co9wZ19Dc5OTmXma3l400CvAV8Drg+M5+IiI8C3wDetzSwI+JoZp5xHrzVauXevXu7auC+XTPcu6/RPZh76uD2mwdynNnZWSYmJgZyrGGwv3qNcm9QR38R0THAm8yBvwi8mJlPlPWHgDcDhyNiQ3nxDcB8r4qVJK1sxQDPzK8B/xIRry9DN9KeTtkNbC1jW4GZvlQoSeqo6ZzE+4BdEXEe8DzwE7TD/8GIuAt4AXhXf0qUJHXSKMAz80nglPkX2lfjkqQh8JOYklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVarR3wOPiIPAfwDfBk5kZisiLgYeADYBB4F3ZebR/pQpSVrubK7AJzPzmiU31twG7MnMK4E9ZV2SNCCrmUK5BdhZlncCt66+HElSU00DPIG/joi5iJgqY+OZ+VJZ/how3vPqJEmnFZm58kYRGzPzUER8D/AY7Zsc787M9Uu2OZqZF3XYdwqYAhgfH98yPT3dVaHzR45z+OWudl2VzRvXDeQ4CwsLjI2NDeRYw2B/9Rrl3qCO/iYnJ+eWTF+f1PSmxofK43xEPAJcCxyOiA2Z+VJEbADmT7PvDmAHQKvVyomJia4auG/XDPfua1RuTx28c2Igx5mdnaXb700N7K9eo9wb1N3filMoEXFhRLx6cRl4G/AUsBvYWjbbCsz0q0hJ0qmaXNKOA49ExOL2f5GZfxUR/wg8GBF3AS8A7+pfmZKk5VYM8Mx8Hnhjh/GvAzf2oyhJ0sr8JKYkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVKNAzwizomIL0TEo2X9ioh4IiIORMQDEXFe/8qUJC13Nlfg7weeXbL+YeAjmfk64ChwVy8LkySdWaMAj4jLgJuBPy3rAdwAPFQ22Qnc2o8CJUmdRWauvFHEQ8BvAa8GfhF4D/C5cvVNRFwOfCozr+6w7xQwBTA+Pr5lenq6q0Lnjxzn8Mtd7boqmzeuG8hxFhYWGBsbG8ixhsH+6jXKvUEd/U1OTs5lZmv5+Io3NY6IHwHmM3MuIibO9sCZuQPYAdBqtXJi4qxfAoD7ds1w774Vy+25g3dODOQ4s7OzdPu9qYH91WuUe4O6+2uSiNcDPxoR7wTOB74b+CiwPiLOzcwTwGXAof6VKUlabsU58My8JzMvy8xNwO3AZzLzTuBx4Lay2VZgpm9VSpJOsZr3gX8Q+EBEHAAuAe7vTUmSpCbOalI5M2eB2bL8PHBt70uSJDXhJzElqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSBrgkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZVqclPj84HPAq8s2z+UmR+KiCuAadp345kD3p2Z3+pnsVK/bNr2yVXtf/fmE7yny9c4uP3mVR1b/381uQL/L+CGzHwjcA3w9oi4Dvgw8JHMfB1wFLirf2VKkpZrclPjzMyFsvqK8pXADcBDZXwncGtfKpQkdRSZufJGEefQniZ5HfBHwO8AnytX30TE5cCnMvPqDvtOAVMA4+PjW6anp7sqdP7IcQ6/3NWuq7J547qBHGdhYYGxsbGBHGsY1np/+w4dX9X+4xfQ9fk5qHOsW2v93261auhvcnJyLjNby8cb3dQ4M78NXBMR64FHgDc0PXBm7gB2ALRarZyYmGi663e4b9cM9+47q3sw98TBOycGcpzZ2Vm6/d7UYK331+389aK7N5/o+vwc1DnWrbX+b7daNfd3Vu9CycxjwOPAW4D1EbF4xl4GHOpxbZKkM1gxwCPiNeXKm4i4ALgJeJZ2kN9WNtsKzPSrSEnSqZr8zLcB2Fnmwb8LeDAzH42IZ4DpiPgN4AvA/X2sU5K0zIoBnplfAt7UYfx54Np+FCVJWpmfxJSkShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEoZ4JJUKQNckiplgEtSpQxwSaqUAS5JlTLAJalSTe7Ic3lEPB4Rz0TE0xHx/jJ+cUQ8FhH7y+NF/S9XkrSoyRX4CeDuzLwKuA742Yi4CtgG7MnMK4E9ZV2SNCArBnhmvpSZny/L/0H7fpgbgVuAnWWzncCt/SpSknSqyMzmG0dsAj4LXA18NTMXb3YcwNHF9WX7TAFTAOPj41ump6e7KnT+yHEOv9zVrquyeeO6gRxnYWGBsbGxgRxrGNZ6f/sOHV/V/uMX0PX5OahzrFv9+Ldb7fe7W52+12v93ASYnJycy8zW8vHGAR4RY8DfAr+ZmQ9HxLGlgR0RRzPzjPPgrVYr9+7de5alt923a4Z79zW5B3NvHdx+80COMzs7y8TExECONQxrvb9N2z65qv3v3nyi6/NzUOdYt/rxb7fa73e3On2v1/q5CRARHQO80btQIuIVwCeAXZn5cBk+HBEbyvMbgPleFStJWlmTd6EEcD/wbGb+3pKndgNby/JWYKb35UmSTqfJz3zXA+8G9kXEk2Xsl4HtwIMRcRfwAvCu/pQoSepkxQDPzL8D4jRP39jbctaeQc3V3b35BO9Zdqy1Pjcqabj8JKYkVcoAl6RKGeCSVCkDXJIqZYBLUqUMcEmqlAEuSZUywCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqtTg71GmNa8ff0K305/L7cQ/oSs15xW4JFWqyS3VPhYR8xHx1JKxiyPisYjYXx7PeDNjSVLvNZlC+TPgD4E/XzK2DdiTmdsjYltZ/2Dvy5PUL02nyppOf2nwVrwCz8zPAkeWDd8C7CzLO4Fbe1yXJGkFkZkrbxSxCXg0M68u68cyc31ZDuDo4nqHfaeAKYDx8fEt09PTXRU6f+Q4h1/uatcqjF/AKf1t3rhuKLXsO3S856/Zqb9Oau25aX+drPWeV9PbWtPpe72wsMDY2NgQqmlucnJyLjNby8dX/S6UzMyIOO3/BTJzB7ADoNVq5cTERFfHuW/XDPfuG903zdy9+cQp/R28c2IotfTjx+VO/XVSa89N++tkrfe8mt7Wmk7f69nZWbrNpWHr9l0ohyNiA0B5nO9dSZKkJroN8N3A1rK8FZjpTTmSpKaavI3w48DfA6+PiBcj4i5gO3BTROwH3lrWJUkDtOLEVmbecZqnbuxxLZKks+AnMSWpUga4JFVqNN4bNKL68UelJI0Or8AlqVJegWtN8acOqTmvwCWpUga4JFXKAJekShngklQpA1ySKmWAS1KlDHBJqpQBLkmVMsAlqVJ+ElMaMj99qm55BS5JlVrVFXhEvB34KHAO8KeZ6Z15JK1ZnX7auXvzib7cyHupg9tv7svrdn0FHhHnAH8EvAO4CrgjIq7qVWGSpDNbzRTKtcCBzHw+M78FTAO39KYsSdJKIjO72zHiNuDtmflTZf3dwA9k5nuXbTcFTJXV1wPPdVnrpcC/d7lvDeyvbqPc3yj3BnX0972Z+Zrlg31/F0pm7gB2rPZ1ImJvZrZ6UNKaZH91G+X+Rrk3qLu/1UyhHAIuX7J+WRmTJA3AagL8H4ErI+KKiDgPuB3Y3ZuyJEkr6XoKJTNPRMR7gU/TfhvhxzLz6Z5VdqpVT8OscfZXt1Hub5R7g4r76/qXmJKk4fKTmJJUKQNckipVRYBHxNsj4rmIOBAR24ZdTxMR8bGImI+Ip5aMXRwRj0XE/vJ4URmPiPiD0t+XIuLNS/bZWrbfHxFbh9FLJxFxeUQ8HhHPRMTTEfH+Mj4SPUbE+RHxDxHxxdLfr5fxKyLiidLHA+UX+ETEK8v6gfL8piWvdU8Zfy4ifng4HZ0qIs6JiC9ExKNlfWR6A4iIgxGxLyKejIi9ZWwkzs+TMnNNf9H+BelXgNcC5wFfBK4adl0N6v4h4M3AU0vGfhvYVpa3AR8uy+8EPgUEcB3wRBm/GHi+PF5Uli8adm+ltg3Am8vyq4F/ov0nFUaix1LnWFl+BfBEqftB4PYy/sfAT5flnwH+uCzfDjxQlq8q5+wrgSvKuXzOsPsrtX0A+Avg0bI+Mr2V+g4Cly4bG4nz82Q/wy6gwT/CW4BPL1m/B7hn2HU1rH3TsgB/DthQljcAz5XlPwHuWL4dcAfwJ0vGv2O7tfQFzAA3jWKPwKuAzwM/QPsTe+eW8ZPnJu13Y72lLJ9btovl5+vS7Ybc02XAHuAG4NFS60j0tqSeTgE+UudnDVMoG4F/WbL+Yhmr0XhmvlSWvwaMl+XT9VhF7+VH6jfRvkodmR7LFMOTwDzwGO0rzGOZeaJssrTWk32U548Dl7B2+/t94JeA/ynrlzA6vS1K4K8jYq78SQ8YofMTvKHD0GRmRkT17+GMiDHgE8DPZ+Y3IuLkc7X3mJnfBq6JiPXAI8AbhlxST0TEjwDzmTkXERPDrqePfjAzD0XE9wCPRcSXlz5Z+/kJdfwSc5Q+sn84IjYAlMf5Mn66Htd07xHxCtrhvSszHy7DI9UjQGYeAx6nPa2wPiIWL3yW1nqyj/L8OuDrrM3+rgd+NCIO0v4rojfQ/rv+o9DbSZl5qDzO0/4f8LWM2PlZQ4CP0kf2dwOLv8XeSnveeHH8x8tvwq8Djpcf8z4NvC0iLiq/LX9bGRu6aF9q3w88m5m/t+SpkegxIl5TrryJiAtoz+8/SzvIbyubLe9vse/bgM9ke9J0N3B7eSfHFcCVwD8MpovOMvOezLwsMzfR/u/pM5l5JyPQ26KIuDAiXr24TPu8eooROT9PGvYkfMNfRryT9rscvgL8yrDraVjzx4GXgP+mPW92F+15wz3AfuBvgIvLtkH75hhfAfYBrSWv85PAgfL1E8Pua0ldP0h7jvFLwJPl652j0iPw/cAXSn9PAb9axl9LO6QOAH8JvLKMn1/WD5TnX7vktX6l9P0c8I5h97aszwn+710oI9Nb6eWL5evpxdwYlfNz8cuP0ktSpWqYQpEkdWCAS1KlDHBJqpQBLkmVMsAlqVIGuCRVygCXpEr9L32kOGhDozVFAAAAAElFTkSuQmCC\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "data.isnull().sum().hist()\n",
        "#numerous null data blocks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gSQkiJ80-FV2",
        "outputId": "fc31a7ed-1d72-4cbc-b020-81ae656f822e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.7.3)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: scikit-optimize in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.0.2)\n",
            "Requirement already satisfied: pyaml>=16.9 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (21.10.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.2.0)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-optimize) (1.7.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.20.0->scikit-optimize) (3.1.0)\n"
          ]
        }
      ],
      "source": [
        "# if you haven't installed xgboost on your system, uncomment the line below\n",
        "!pip install xgboost\n",
        "# if you haven't installed bayesian-optimization on your system, uncomment the line below\n",
        "!pip install scikit-optimize"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I-_dFZnX-FV2"
      },
      "outputs": [],
      "source": [
        "#split the features and labels\n",
        "x = data.drop('match', axis=1)\n",
        "#split the numeric features and categorical data\n",
        "features_numeric = list(x.select_dtypes(include=['float64']))\n",
        "features_categorical = list(x.select_dtypes(include=['object']))\n",
        "#get the labels\n",
        "y = data['match']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y2-MN8Nw-FV2",
        "outputId": "4760fca1-436e-4a06-ebf9-d90d1c6e9781"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['field', 'undergra', 'mn_sat', 'tuition', 'from', 'zipcode', 'income', 'career']\n"
          ]
        }
      ],
      "source": [
        "#print the categorical feature names\n",
        "print(features_categorical)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now based on the template, try to improve the model's performance on the public leaderboard by following the data science life-cycle for tuning. You can try different features, different hyperparameters/configurations of the model, and even a different model. For each trial, document the reason why you want to make the certain change and the expected outcome, before running the code. Record the observed performance and your thought on it. The final result is not important, but the process is. Documentation of your thought process is very important, since most people forgot why they test certain model/hyperparameter after they got the result (it takes time). It also helps a lot when you got stuck. You can organize the notebook by listing\n",
        "\n",
        "thoughts and observations for trial 0, plan for trial 1\n",
        "code for trial 1\n",
        "thoughts and observations for trial 1, plan for trial 2\n",
        "code for trial 2\n",
        "â€¦\n",
        "You have to tune at least 6 times. All the tried solutions should be different (e.g. different feature sets/different preprocessing/model/tuning method/tuning range). Requirements - covered at least:\n",
        "\n",
        "one grid search trial,\n",
        "and one random search trial,\n",
        "and one bayesian search trial"
      ],
      "metadata": {
        "id": "IFXfaTpCqvej"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3hESIzL-FV3"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost.sklearn import XGBClassifier\n",
        "\n",
        "np.random.seed(0)\n",
        "#deal with the numeric vlaues\n",
        "transformer_numeric = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='median')),#replace the missing value with the median value in this feature\n",
        "        ('scaler', StandardScaler())]\n",
        ")\n",
        "#deal with the categorical values\n",
        "transformer_categorical = Pipeline(\n",
        "    steps=[\n",
        "        ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),#fill the missing value with 'missing' and then replace the label with a constant numeric value\n",
        "        ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "    ]\n",
        ")\n",
        "#combine the two pipeline above together\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', transformer_numeric, features_numeric),\n",
        "        ('cat', transformer_categorical, features_categorical)\n",
        "    ]\n",
        ")\n",
        "#final pipeline\n",
        "full_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('my_classifier', XGBClassifier(\n",
        "            objective='binary:logistic', seed=1))#It is a binary classification problem\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example run of gridsearch\n",
        "# `__` denotes attribute \n",
        "# (e.g. my_classifier__n_estimators means the `n_estimators` param for `my_classifier`\n",
        "#  which is our xgb)\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [10, 20, 100],\n",
        "    'my_classifier__max_depth':[10, 20]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y)\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2lZn1QbMyz-C",
        "outputId": "869d2fbb-d7f0-440b-9d15-af310a2a3652"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "best score 0.8789401909943632\n",
            "best score {'my_classifier__max_depth': 10, 'my_classifier__n_estimators': 100, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 1\n",
        "#increase the number of choices for the parameters and see if it reaches the best selection of these parameters\n",
        "#increase depth and estimator number\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [20, 100, 200],\n",
        "    'my_classifier__max_depth':[30,40]}\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y)\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))\n",
        "# the result had slight increase as the depth and estimators increase\n",
        "#but the running time increases from 2 mins to 6 mins"
      ],
      "metadata": {
        "id": "SFKOsnXH4Ee6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "228eb9ba-02f4-4394-fc25-19b26df6cb6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n",
            "best score 0.8808741520245137\n",
            "best score {'my_classifier__max_depth': 40, 'my_classifier__n_estimators': 200, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 2\n",
        "#the increase in accuracy is too little to measure for the last trial\n",
        "#to improve efficiency, let's try multiple learning rate setting, lower maximum depth and try to tweak the loss function\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [50,80,100],\n",
        "    'my_classifier__max_depth':[2,3,5],\n",
        "    'my_classifier__learning_rate':[0.05,0.1,0.2],#learning rate\n",
        "    'my_classifier__reg_alpha':[2,5,8],#loss function\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y)\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))\n",
        "#more increase in scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fe62b57-5de6-4267-a492-5369ebe99213",
        "id": "0SqUJZbXAcgD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n",
            "best score 0.8821970573122855\n",
            "best score {'my_classifier__learning_rate': 0.1, 'my_classifier__max_depth': 5, 'my_classifier__n_estimators': 80, 'my_classifier__reg_alpha': 2, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "mdkka_LF-FV2",
        "outputId": "890e216f-f719-44cb-cdd0-50d2f23956e5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f5360347e10>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "data['match'].hist()\n",
        "#match score is binary"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 3\n",
        "#As seen in the diagram aove, the positive sample (1) is significantly lower than that of negative samples(0)\n",
        "#Thus the scale_pos_weight attribute may need to be adjusted\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [100],\n",
        "    'my_classifier__max_depth':[3],\n",
        "    'my_classifier__learning_rate':[0.1],#learning rate\n",
        "    'my_classifier__reg_alpha':[5],#loss function\n",
        "    'my_classifier__scale_pos_weight':[0.2,0.4,0.6,1,2,3,4,5]#the pos/neg sample ratio\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y)\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))\n",
        "#no change in scores since the scale is the best as default"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9ed8fa1-5ba1-4183-e258-47d3344952f6",
        "id": "VHukz1VWDD2H"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 8 candidates, totalling 40 fits\n",
            "best score 0.8768925286826104\n",
            "best score {'my_classifier__learning_rate': 0.1, 'my_classifier__max_depth': 3, 'my_classifier__n_estimators': 100, 'my_classifier__reg_alpha': 5, 'my_classifier__scale_pos_weight': 4, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#random search trial 1\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [50,80,100],\n",
        "    'my_classifier__max_depth':[2,3,5],\n",
        "    'my_classifier__learning_rate':[0.1],#learning rate\n",
        "    'my_classifier__reg_alpha':[2,5,8]#loss function\n",
        "}\n",
        "#nearly the same layout as gridsearch\n",
        "random_search = RandomizedSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "random_search.fit(x, y)\n",
        "print('best score {}'.format(random_search.best_score_))\n",
        "print('best score {}'.format(random_search.best_params_))\n",
        "#not much difference with the grid search trial"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e565d801-827f-4d29-ab90-b7a51eb8d808",
        "id": "j1O7dLM9KupG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
            "best score 0.8817523075219587\n",
            "best score {'preprocessor__num__imputer__strategy': 'mean', 'my_classifier__reg_alpha': 2, 'my_classifier__n_estimators': 100, 'my_classifier__max_depth': 5, 'my_classifier__learning_rate': 0.1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oRt1fiYJ-FV4",
        "outputId": "894aa257-2dbe-4598-b0ea-aacb05f6967e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.352718564818733, my_svc__degree=6, my_svc__gamma=0.022854318128961743, my_svc__kernel=poly;, score=0.830 total time=  11.3s\n",
            "[CV 2/5] END my_svc__C=2.352718564818733, my_svc__degree=6, my_svc__gamma=0.022854318128961743, my_svc__kernel=poly;, score=0.812 total time=   9.7s\n",
            "[CV 3/5] END my_svc__C=2.352718564818733, my_svc__degree=6, my_svc__gamma=0.022854318128961743, my_svc__kernel=poly;, score=0.818 total time=  10.0s\n",
            "[CV 4/5] END my_svc__C=2.352718564818733, my_svc__degree=6, my_svc__gamma=0.022854318128961743, my_svc__kernel=poly;, score=0.821 total time=  14.0s\n",
            "[CV 5/5] END my_svc__C=2.352718564818733, my_svc__degree=6, my_svc__gamma=0.022854318128961743, my_svc__kernel=poly;, score=0.832 total time=  11.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=0.0012602593949011189, my_svc__degree=8, my_svc__gamma=2.285959941576884, my_svc__kernel=poly;, score=0.838 total time=  11.5s\n",
            "[CV 2/5] END my_svc__C=0.0012602593949011189, my_svc__degree=8, my_svc__gamma=2.285959941576884, my_svc__kernel=poly;, score=0.814 total time=   9.2s\n",
            "[CV 3/5] END my_svc__C=0.0012602593949011189, my_svc__degree=8, my_svc__gamma=2.285959941576884, my_svc__kernel=poly;, score=0.821 total time=   9.2s\n",
            "[CV 4/5] END my_svc__C=0.0012602593949011189, my_svc__degree=8, my_svc__gamma=2.285959941576884, my_svc__kernel=poly;, score=0.822 total time=  12.2s\n",
            "[CV 5/5] END my_svc__C=0.0012602593949011189, my_svc__degree=8, my_svc__gamma=2.285959941576884, my_svc__kernel=poly;, score=0.832 total time=  12.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.2095350994035026, my_svc__degree=1, my_svc__gamma=0.0002488766453161173, my_svc__kernel=linear;, score=0.806 total time=  10.3s\n",
            "[CV 2/5] END my_svc__C=2.2095350994035026, my_svc__degree=1, my_svc__gamma=0.0002488766453161173, my_svc__kernel=linear;, score=0.790 total time=  11.8s\n",
            "[CV 3/5] END my_svc__C=2.2095350994035026, my_svc__degree=1, my_svc__gamma=0.0002488766453161173, my_svc__kernel=linear;, score=0.793 total time=  10.5s\n",
            "[CV 4/5] END my_svc__C=2.2095350994035026, my_svc__degree=1, my_svc__gamma=0.0002488766453161173, my_svc__kernel=linear;, score=0.790 total time=  13.3s\n",
            "[CV 5/5] END my_svc__C=2.2095350994035026, my_svc__degree=1, my_svc__gamma=0.0002488766453161173, my_svc__kernel=linear;, score=0.796 total time=  14.0s\n",
            "best score 0.8255215474568427\n",
            "best score OrderedDict([('my_svc__C', 0.0012602593949011189), ('my_svc__degree', 8), ('my_svc__gamma', 2.285959941576884), ('my_svc__kernel', 'poly')])\n"
          ]
        }
      ],
      "source": [
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Categorical, Integer\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "\n",
        "SVC_pipline = Pipeline(\n",
        "    steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('my_svc', SVC(class_weight='balanced'))\n",
        "    ]\n",
        ")\n",
        "# SVC has a class_weight attribute for unbalanced data\n",
        "\n",
        "\n",
        "# define ranges for bayes search\n",
        "bayes_search = BayesSearchCV(\n",
        "    SVC_pipline,\n",
        "    {\n",
        "        'my_svc__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "        'my_svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "        'my_svc__degree': Integer(1,8),\n",
        "        'my_svc__kernel': Categorical(['linear', 'poly', 'rbf']),\n",
        "    },\n",
        "    n_iter=3,\n",
        "    random_state=0,\n",
        "    verbose=3,\n",
        ")\n",
        "\n",
        "bayes_search.fit(x, y)\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jG6qwl9F-FV4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4847216a-047d-4c60-b08c-e53efd50c0f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.840 total time=   9.5s\n",
            "[CV 2/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.821 total time=   9.6s\n",
            "[CV 3/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.825 total time=  12.8s\n",
            "[CV 4/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.831 total time=  12.8s\n",
            "[CV 5/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.829 total time=  12.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.839 total time=   9.9s\n",
            "[CV 2/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.818 total time=   9.9s\n",
            "[CV 3/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.822 total time=  13.4s\n",
            "[CV 4/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.829 total time=  13.3s\n",
            "[CV 5/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.831 total time=  13.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.833 total time=  10.9s\n",
            "[CV 2/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  10.8s\n",
            "[CV 3/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  10.9s\n",
            "[CV 4/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  11.2s\n",
            "[CV 5/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.833 total time=  12.7s\n",
            "best score 0.8327974944517754\n",
            "best score OrderedDict([('my_svc__C', 2.2095350994035026), ('my_svc__coef0', 0.05789784369353025), ('my_svc__degree', 11), ('my_svc__gamma', 2.189069216928205e-05), ('my_svc__kernel', 'poly')])\n"
          ]
        }
      ],
      "source": [
        "#trial 1 bayes search\n",
        "#since the polynomial kernel is the best fit, the best coefficient needed to be adjusted for the model\n",
        "#Increase in degree might improve the result too\n",
        "bayes_search = BayesSearchCV(\n",
        "    SVC_pipline,\n",
        "    {\n",
        "        'my_svc__C': Real(1e-6, 1e+6, prior='log-uniform'),#regularization parameter\n",
        "        'my_svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'),#kernel coefficient\n",
        "        'my_svc__degree': Integer(8,16),#degree of polynomial\n",
        "        'my_svc__kernel': Categorical([ 'poly']),#kernel category\n",
        "        'my_svc__coef0': Real(0,1) #polynomial coefficient\n",
        "    },\n",
        "    n_iter=3,\n",
        "    random_state=0,\n",
        "    verbose=3,\n",
        ")\n",
        "\n",
        "bayes_search.fit(x, y)\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n",
        "#improves in the scores"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#trial 2 bayes search\n",
        "#Increasing the number of iterations and lets see if the score improves\n",
        "bayes_search = BayesSearchCV(\n",
        "    SVC_pipline,\n",
        "    {\n",
        "        'my_svc__C': Real(1e-6, 1e+6, prior='log-uniform'),\n",
        "        'my_svc__gamma': Real(1e-6, 1e+1, prior='log-uniform'),\n",
        "        'my_svc__degree': Integer(8,16),\n",
        "        'my_svc__kernel': Categorical([ 'poly']),\n",
        "        'my_svc__coef0': Real(0,1)\n",
        "    },\n",
        "    n_iter=6,#iterations increases may lead to increase in score if underfitting as bayesian search learns from previous iterations\n",
        "    random_state=0,\n",
        "    verbose=3,\n",
        ")\n",
        "\n",
        "bayes_search.fit(x, y)\n",
        "print('best score {}'.format(bayes_search.best_score_))\n",
        "print('best score {}'.format(bayes_search.best_params_))\n",
        "#slightly improves the scores,not much is done\n",
        "#it could be considerred that the model is already fitting itself"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBvagWWEVcKX",
        "outputId": "1be4ffa8-9385-49f2-d173-8df8ace12f23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.840 total time=   9.3s\n",
            "[CV 2/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.821 total time=   9.5s\n",
            "[CV 3/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.825 total time=  12.9s\n",
            "[CV 4/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.831 total time=  11.3s\n",
            "[CV 5/5] END my_svc__C=2.352718564818733, my_svc__coef0=0.6760795088769136, my_svc__degree=13, my_svc__gamma=0.033632533813774734, my_svc__kernel=poly;, score=0.829 total time=  12.8s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.839 total time=   9.9s\n",
            "[CV 2/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.818 total time=   9.8s\n",
            "[CV 3/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.822 total time=  13.2s\n",
            "[CV 4/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.829 total time=  13.3s\n",
            "[CV 5/5] END my_svc__C=0.0012602593949011189, my_svc__coef0=0.9789036584263616, my_svc__degree=15, my_svc__gamma=0.01568172826980749, my_svc__kernel=poly;, score=0.831 total time=  13.5s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.833 total time=  10.7s\n",
            "[CV 2/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  10.8s\n",
            "[CV 3/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  10.7s\n",
            "[CV 4/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.832 total time=  12.1s\n",
            "[CV 5/5] END my_svc__C=2.2095350994035026, my_svc__coef0=0.05789784369353025, my_svc__degree=11, my_svc__gamma=2.189069216928205e-05, my_svc__kernel=poly;, score=0.833 total time=  11.4s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=5.87540411933884e-05, my_svc__coef0=0.7832662706729938, my_svc__degree=12, my_svc__gamma=0.0015324556561035888, my_svc__kernel=poly;, score=0.835 total time=  11.0s\n",
            "[CV 2/5] END my_svc__C=5.87540411933884e-05, my_svc__coef0=0.7832662706729938, my_svc__degree=12, my_svc__gamma=0.0015324556561035888, my_svc__kernel=poly;, score=0.832 total time=  10.9s\n",
            "[CV 3/5] END my_svc__C=5.87540411933884e-05, my_svc__coef0=0.7832662706729938, my_svc__degree=12, my_svc__gamma=0.0015324556561035888, my_svc__kernel=poly;, score=0.832 total time=  10.9s\n",
            "[CV 4/5] END my_svc__C=5.87540411933884e-05, my_svc__coef0=0.7832662706729938, my_svc__degree=12, my_svc__gamma=0.0015324556561035888, my_svc__kernel=poly;, score=0.831 total time=  10.9s\n",
            "[CV 5/5] END my_svc__C=5.87540411933884e-05, my_svc__coef0=0.7832662706729938, my_svc__degree=12, my_svc__gamma=0.0015324556561035888, my_svc__kernel=poly;, score=0.833 total time=  11.3s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=0.0006168340492440594, my_svc__coef0=0.243335935468399, my_svc__degree=14, my_svc__gamma=9.971554009280314e-05, my_svc__kernel=poly;, score=0.833 total time=  11.9s\n",
            "[CV 2/5] END my_svc__C=0.0006168340492440594, my_svc__coef0=0.243335935468399, my_svc__degree=14, my_svc__gamma=9.971554009280314e-05, my_svc__kernel=poly;, score=0.832 total time=  11.0s\n",
            "[CV 3/5] END my_svc__C=0.0006168340492440594, my_svc__coef0=0.243335935468399, my_svc__degree=14, my_svc__gamma=9.971554009280314e-05, my_svc__kernel=poly;, score=0.832 total time=  10.9s\n",
            "[CV 4/5] END my_svc__C=0.0006168340492440594, my_svc__coef0=0.243335935468399, my_svc__degree=14, my_svc__gamma=9.971554009280314e-05, my_svc__kernel=poly;, score=0.832 total time=  10.7s\n",
            "[CV 5/5] END my_svc__C=0.0006168340492440594, my_svc__coef0=0.243335935468399, my_svc__degree=14, my_svc__gamma=9.971554009280314e-05, my_svc__kernel=poly;, score=0.167 total time=  10.7s\n",
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "[CV 1/5] END my_svc__C=11428.693628355693, my_svc__coef0=0.9912240538928986, my_svc__degree=14, my_svc__gamma=0.0025305221847832585, my_svc__kernel=poly;, score=0.849 total time=   5.0s\n",
            "[CV 2/5] END my_svc__C=11428.693628355693, my_svc__coef0=0.9912240538928986, my_svc__degree=14, my_svc__gamma=0.0025305221847832585, my_svc__kernel=poly;, score=0.836 total time=   5.1s\n",
            "[CV 3/5] END my_svc__C=11428.693628355693, my_svc__coef0=0.9912240538928986, my_svc__degree=14, my_svc__gamma=0.0025305221847832585, my_svc__kernel=poly;, score=0.836 total time=   5.0s\n",
            "[CV 4/5] END my_svc__C=11428.693628355693, my_svc__coef0=0.9912240538928986, my_svc__degree=14, my_svc__gamma=0.0025305221847832585, my_svc__kernel=poly;, score=0.835 total time=   4.9s\n",
            "[CV 5/5] END my_svc__C=11428.693628355693, my_svc__coef0=0.9912240538928986, my_svc__degree=14, my_svc__gamma=0.0025305221847832585, my_svc__kernel=poly;, score=0.834 total time=   4.9s\n",
            "best score 0.8380429845939158\n",
            "best score OrderedDict([('my_svc__C', 11428.693628355693), ('my_svc__coef0', 0.9912240538928986), ('my_svc__degree', 14), ('my_svc__gamma', 0.0025305221847832585), ('my_svc__kernel', 'poly')])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a result ,we select the result from gridsearch in the second trial and prepare our submission."
      ],
      "metadata": {
        "id": "_Y1GA_-2o0DY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k6wJ28S6-FV4"
      },
      "outputs": [],
      "source": [
        "# print('all the cv scores')\n",
        "# pprint(bayes_search.cv_results_)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Final submission\n",
        "#the increase in accuracy is too little to measure for the last trial\n",
        "#to improve efficiency, let's try multiple learning rate setting, lower maximum depth and try to tweak the loss function\n",
        "param_grid = {\n",
        "    'preprocessor__num__imputer__strategy': ['mean'],\n",
        "    'my_classifier__n_estimators': [80],\n",
        "    'my_classifier__max_depth':[5],\n",
        "    'my_classifier__learning_rate':[0.1],#learning rate\n",
        "    'my_classifier__reg_alpha':[2],#loss function\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    full_pipline, param_grid, cv=5, verbose=3, n_jobs=2, \n",
        "    scoring='roc_auc')\n",
        "\n",
        "grid_search.fit(x, y)\n",
        "print('best score {}'.format(grid_search.best_score_))\n",
        "print('best score {}'.format(grid_search.best_params_))\n",
        "#slight increase in scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b383f975-3b69-40a7-dea4-b1e5cb65dbd5",
        "id": "waf7YDq8pDXn"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
            "best score 0.8821970573122855\n",
            "best score {'my_classifier__learning_rate': 0.1, 'my_classifier__max_depth': 5, 'my_classifier__n_estimators': 80, 'my_classifier__reg_alpha': 2, 'preprocessor__num__imputer__strategy': 'mean'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "VkYab9MQ-FV3",
        "outputId": "ed6d00e1-287d-4fe0-bfd7-abe2c154697f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id     match\n",
              "0      934  0.079463\n",
              "1     6539  0.481633\n",
              "2     6757  0.261872\n",
              "3     2275  0.059485\n",
              "4     1052  0.042743\n",
              "...    ...       ...\n",
              "2464  7982  0.202070\n",
              "2465  7299  0.341643\n",
              "2466  1818  0.090478\n",
              "2467   937  0.030958\n",
              "2468  6691  0.016516\n",
              "\n",
              "[2469 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-026ce0cb-3222-40ed-9edc-40f695e9fec7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>match</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>934</td>\n",
              "      <td>0.079463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>6539</td>\n",
              "      <td>0.481633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6757</td>\n",
              "      <td>0.261872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2275</td>\n",
              "      <td>0.059485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1052</td>\n",
              "      <td>0.042743</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2464</th>\n",
              "      <td>7982</td>\n",
              "      <td>0.202070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2465</th>\n",
              "      <td>7299</td>\n",
              "      <td>0.341643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2466</th>\n",
              "      <td>1818</td>\n",
              "      <td>0.090478</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2467</th>\n",
              "      <td>937</td>\n",
              "      <td>0.030958</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2468</th>\n",
              "      <td>6691</td>\n",
              "      <td>0.016516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2469 rows Ã— 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-026ce0cb-3222-40ed-9edc-40f695e9fec7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-026ce0cb-3222-40ed-9edc-40f695e9fec7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-026ce0cb-3222-40ed-9edc-40f695e9fec7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "#prepare submission:\n",
        "submission = pd.DataFrame()\n",
        "submission['id'] = data_test['id']\n",
        "submission['match'] = grid_search.predict_proba(data_test)[:,1]\n",
        "submission.to_csv('sample_submission_walkthrough.csv', index=False)\n",
        "submission"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Q:ðŸŒˆWhy a simple linear regression model (without any activation function) is not good for classification task, compared to Perceptron/Logistic regression?<br>\n",
        "A: Because simple linear regression model deals with coninuous values whereas in a classification task, discrete values are handled. Perceptron deals with binary class label which are discrete values.<br>\n",
        "ðŸŒˆWhat's a decision tree and how it is different to a logistic regression model?<br>\n",
        "Aï¼šDecsion tree performs like a flow chart and evey node on it tests the result from pervious node. After the test, the result is shown by the node extending branches to other node. Compare to logistic regression model, decision tree doesn't aim to divide the data points into two or three catergories but to divide them up to a number of small blocks by coninously splitting them.<br>\n",
        "ðŸŒˆWhat's the difference between grid search and random search?<br>\n",
        "A: Random search searches the datapoints/nodes randomly in batches, that means not all datapoints are evualuated in one iteration. Grid search has certain order to loop through all the datapoints.<br>\n",
        "ðŸŒˆWhat's the difference between bayesian search and random search?<br>\n",
        "Aï¼šBayesian search runs their iterations depend on pevious iteration, whereas in random search each iterations is independent."
      ],
      "metadata": {
        "id": "7fePO1l4iAEx"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "slDVibZz-FV4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.8"
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}